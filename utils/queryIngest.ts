"use server";

import { Index as UpstashIndex } from "@upstash/vector";

import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const index = new UpstashIndex({
  url: process.env.UPSTASH_VECTOR_REST_URL,
  token: process.env.UPSTASH_VECTOR_REST_TOKEN,
});

type JournalMetadata = {
  id?: string;
  createdAt?: string;
  userId?: string;
  tags?: string;
  title?: string;
  content?: string;
};

export const queryJournals = async (
  query: string,
  filters?: Partial<JournalMetadata>,
  topK: number = 5,
) => {
  // Build filter string if filters provided
  let filterStr = "";
  if (filters) {
    const filterParts = Object.entries(filters)
      .filter(([_, value]) => value !== undefined)
      .map(([key, value]) => `${key}='${value}'`);

    if (filterParts.length > 0) {
      filterStr = filterParts.join(" AND ");
    }
  }

  try {
    // Query the vector store
    const results = await index.query({
      data: query,
      topK,
      filter: filterStr || undefined,
      includeMetadata: true,
      includeData: true,
    });

    // Combine the content of the most relevant documents
    const relevantDocs = results.map((match) => match.metadata);
    console.log(relevantDocs)
    const combinedContent = relevantDocs
      .map(
        (doc) =>
          `${doc.title || "Untitled"} (Tags: ${doc.tags || "N/A"}): ${doc.content}`,
      )
      .join("\n\n");

    // Send combined content to OpenAI for generating an answer
    const prompt = `
      Answer the following question based on these journal entries:

      ${combinedContent}

      Question: ${query}
    `;

    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini", // Specify the model you want to use
      messages: [
        {
          role: "system",
          content:
            "You are a helpful assistant answering questions based on journal entries.",
        },
        { role: "user", content: prompt },
      ],
      max_tokens: 200, // Adjust token limit as needed
      temperature: 0.1, // Adjust temperature for more creative or factual responses
    });

    // Return the answer generated by OpenAI
    return response.choices[0].message.content || "No answer generated.";
  } catch (error) {
    console.error("Error during query processing:", error);
    throw error;
  }
};
